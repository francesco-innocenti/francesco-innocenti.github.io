---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi! Iâ€™m Francesco.

Iâ€™m currently a PhD student in Machine Learning and Theoretical Neuroscience at the University of Sussex, supervised 
by [Christopher Buckley](https://scholar.google.com/citations?user=nWuZ0XcAAAAJ&hl=en&oi=ao) and [Anil Seth
](https://scholar.google.com/citations?user=3eJCZCkAAAAJ&hl=en&oi=ao). 
My research interests include biologically plausible learning (how to make artificial neural networks learn more like 
brains) and deep learning theory (understanding how modern deep networks work in the first place).

I recently interned as an Applied Scientist at Amazon, helping to improve their model forecasts to deliver packages 
throughout Europe more efficiently. During my undergrad, I worked as a research assistant in [Ashok Jansari](https://scholar.google.com/citations?hl=en&user=vwtx4TsAAAAJ&view_op=list_works&sortby=pubdate)â€™s 
lab at Goldsmiths, University of London, helping to develop a face memory test aimed at people with both poor and 
exceptional face recognition abilities. I also interned in the lab of [Devin Terhune](https://scholar.google.com/citations?user=rBgJFwYAAAAJ&hl=en&oi=ao), 
using machine learning tools to differentiate the subjective experiences associated with different psychedelic drugs.

Outside of work, I enjoy running, swimming and playing football, and am always up for a physical challenge!

-----------

# News

## ğŸ’»â€ Introducing JPC
*December 2024*

<p align="center">
  <img src="../images/jpc.png" width="200">
</p>

â­ï¸ Our lab just released [JPC
](https://github.com/thebuckleylab/jpc), a **J**AX library for training neural 
networks with **P**redictive **C**oding. See this [pre-print
](https://arxiv.org/abs/2412.03676) for more details.

## ğŸ‡¨ğŸ‡¦ Paper accepted at NeurIPS 2024
*September 2024*

<p align="center">
  <img src="../images/NeurIPS_2024_poster.png" width="700">
</p>

Our paper [Only Strict Saddles in the Energy Landscape of Predictive Coding Networks?
](https://arxiv.org/abs/2408.11979) has been accepted at NeurIPS 2024! See [this blog post](https://francesco-innocenti.github.io/posts/2024/10/01/The-Energy-Landscape-of-Predictive-Coding-Networks/) 
for the key takeaways.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Excited to share that our paper â€œOnly Strict Saddles in the Energy Landscape of Predictive Coding Networks?â€ (<a href="https://t.co/QH6BEe8XCR">https://t.co/QH6BEe8XCR</a>) has been accepted at <a href="https://twitter.com/hashtag/NeurIPS2024?src=hash&amp;ref_src=twsrc%5Etfw">#NeurIPS2024</a> ğŸ‡¨ğŸ‡¦<br><br>ğŸ“– TL;DR: We show that PC makes the loss landscape of deep neural networks more benign.<br><br>ğŸ‘‡ğŸ§µ</p>&mdash; Francesco Innocenti (@InnocFrancesco) <a href="https://twitter.com/InnocFrancesco/status/1839695842279674119?ref_src=twsrc%5Etfw">September 27, 2024</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


## ğŸ‡ªğŸ‡¸ Applied Scientist Intern at Amazon
*April 2024*

<p align="center">
<img src="https://raw.githubusercontent.com/francesco-innocenti/francesco-innocenti.github.io/master/_posts/imgs/amazon_logo.png" width="200" >
</p>

I recently completed an internship as Applied Scientist at Amazon, in Barcelona. 
I wrote about my experience [here](https://francesco-innocenti.github.io/posts/2024/04/27/Amazon-Internship/) 
if you're interested.


## ğŸ† Best Workshop Paper Award at ICML 2023
*June 2023*

<p align="center">
  <img src="../images/pc_trust_region_toy.png" width="700">
</p>

I will be at ICML 2023 in Hawaii to present my work on [Understanding Predictive Coding as a Second-Order Trust-Region Method](https://openreview.net/forum?id=x7PUpFKZ8M), 
which won a Best Paper Award at the [Workshop on Localized Learning](https://sites.google.com/view/localized-learning-workshop).
You can rewatch my talk [here](https://icml.cc/virtual/2023/workshop/21484) or read [my blog post](https://francesco-innocenti.github.io/posts/2023/08/10/PC-as-a-2nd-Order-Method/)
for the key ideas.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Honoured to share that my first PhD paper &quot;Understanding Predictive Coding as a Second-Order Trust-Region Method&quot; (<a href="https://t.co/xP3m0aZS99">https://t.co/xP3m0aZS99</a>) won a Best Paper Award at the ICML 2023 Workshop on Localized Learning! ğŸ‰ <a href="https://twitter.com/hashtag/icml2023?src=hash&amp;ref_src=twsrc%5Etfw">#icml2023</a><br><br>If this piques your interest, read on 1/14ğŸ‘‡ğŸ§µ</p>&mdash; Francesco Innocenti (@InnocFrancesco) <a href="https://twitter.com/InnocFrancesco/status/1680981476672774144?ref_src=twsrc%5Etfw">July 17, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
