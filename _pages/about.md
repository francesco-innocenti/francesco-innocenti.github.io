---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


Hi! I‚Äôm Francesco.

I am currently a Postdoctoral Researcher at the University of Oxford in 
the group of [Rafal Bogacz](https://scholar.google.com/citations?user=m02-44gAAAAJ&hl=en&oi=ao). 
Previously, I did my PhD in Machine Learning and Theoretical Neuroscience at the 
University of Sussex, supervised by [Christopher Buckley](https://scholar.google.com/citations?user=nWuZ0XcAAAAJ&hl=en&oi=ao) 
and [Anil Seth](https://scholar.google.com/citations?user=3eJCZCkAAAAJ&hl=en&oi=ao). 
I also interned as an Applied Scientist at Amazon, helping to improve their 
model forecasts to deliver packages throughout Europe more efficiently.

My research focuses on understanding the training dynamics and scaling 
behaviour of artificial and biological neural networks. I like to understand 
things through the lens of optimisation theory, and am broadly interested in 
energy-based models, time-series forecasting, and all things AI-related.

Outside of work, I enjoy swimming and calisthenics, and am always up for a 
physical challenge!

-----------

# News

* **[Feb 2026] New preprint** [On the Infinite Width and Depth Limits of Predictive Coding Networks](https://arxiv.org/abs/2602.07697)
* **[Nov 2025] üá¨üáß Postdoctoral Researcher, University of Oxford**. Joining the 
group of Professor [Rafal Bogacz](https://scholar.google.com/citations?user=m02-44gAAAAJ&hl=en&oi=ao) 
to conduct research in theoretical neuroscience and machine learning.
* **[Oct 2025] üá≤üá¶ Visiting Researcher, UM6P (Morocco)**. Collaborating with [El Mehdi Achour](https://scholar.google.com/citations?user=A-i6nwgAAAAJ&hl=en) on LLM mixture of experts.
* **[Sept 2025] üá∫üá∏ Two Papers Accepted at NeurIPS 2025 (San Diego)**
  * **Main track**: [ŒºPC: Scaling Predictive Coding to 100+ Layer Networks](https://openreview.net/forum?id=lSLSzYuyfX&referrer=%5Bthe%20profile%20of%20Francesco%20Innocenti%5D(%2Fprofile%3Fid%3D~Francesco_Innocenti1))
  ---introduces a reparameterisation of predictive coding networks that allows 
  stable training of 100+ layer models on simple tasks with hyperparameter transfer.
  * **Workshop**: [A Simple Generalisation of the Implicit Dynamics of In-Context Learning](https://arxiv.org/abs/2512.11255)
  ---extends a recent result on the theory of in-context learning in transformers.
* **[Jul 2025] Publication in the Journal of Statistical Mechanics: Theory and Experiment**. 
  A slightly updated version of our NeuIPS 2024 paper on the geometry of the 
  energy landscape of predictive coding networks has just been republished [here](https://iopscience.iop.org/article/10.1088/1742-5468/ade2eb).
* **[Dec 2024] ‚Äçüíª ‚ÄçSoftware release**. We introduce [JPC](https://github.com/thebuckleylab/jpc),
  a **J**AX library for training neural networks with **P**redictive **C**oding.
* **[Sept 2024] üá®üá¶ Paper accepted at NeurIPS 2024**. [Only Strict Saddles in the Energy Landscape of Predictive Coding Networks?](https://papers.nips.cc/paper_files/paper/2024/hash/6075fc6540b9a3cb951752099efd86ef-Abstract-Conference.html)
  ---See [the blog post](https://francesco-innocenti.github.io/posts/2024/10/01/The-Energy-Landscape-of-Predictive-Coding-Networks/) 
  for the key takeaways.
* **[Apr 2024] üá™üá∏ Applied Scientist Intern, Amazon (Barcelona)**. Completed an 
  intership focusing on applied ML. Read about my experience [here](https://francesco-innocenti.github.io/posts/2024/04/27/Amazon-Internship/).
* **[Jun 2023] üèÜ Best Workshop Paper Award at ICML 2023 (Hawaii)**. Our work on 
  [Understanding Predictive Coding as a Second-Order Trust-Region Method](https://openreview.net/forum?id=x7PUpFKZ8M) 
  won a Best Paper Award at the ICML [Workshop on Localized Learning](https://sites.google.com/view/localized-learning-workshop).
  * [Watch the talk]((https://icml.cc/virtual/2023/workshop/21484)) or [read the blog post]((https://francesco-innocenti.github.io/posts/2023/08/10/PC-as-a-2nd-Order-Method/)).
